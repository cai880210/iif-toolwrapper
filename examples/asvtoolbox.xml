<?xml version="1.0" encoding="UTF-8"?>
<toolspec model="0.1" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:noNamespaceSchemaLocation="../src/main/resources/toolspec.xsd">
    <id>asvtoolbox</id>
    <name>ASV Toolbox</name>
    <homepage>http://wortschatz.uni-leipzig.de/~cbiemann/software/toolbox/</homepage>
    <version>1-0</version>
    <installation>
        <os type="linux">
            Requires Java. The ASV Toolbox is available from here: http://wortschatz.uni-leipzig.de/~cbiemann/software/toolbox/.
        </os>
        <os type="windows">
            Requires Java. The ASV Toolbox is available from here: http://wortschatz.uni-leipzig.de/~cbiemann/software/toolbox/.
        </os>
    </installation>
    <services>
        <service sid="1" name="ASV_chineseWhispers" type="migrate" servicepackage="eu.impact_project.iif.service" contextpathprefix="/impactservices">
            <description>Service for efficient graph clustering</description>
            <operations>
                <operation oid="1" name="chineseWhispers">
                    <description>Cluster undirected, weighted graphs</description>
                    <!--
                    Usage:
                    java -Xmx500M -classpath .;./lib/ASV_CW.jar -Djava.ext.dirs=.;./lib de.uni_leipzig.asv.toolbox.ChineseWhispers.main.Start -F -i examples\7lang_nodes.txt -o 7lang_result.txt

                    -H | -h | --help   Writes out this Help.
                    -D Use database specified in CW_DBproperties.ini as input.
                    -F Use files specified by -i as input.
                    -i Use files as input.
                    filename1  The node list 2-col.
                    filename2  The edge list 3-col.
                    -a Sets the algorithm options
                    "top"
                    "dist_nolog"
                    "dist_log"
                    "vote x" with x in [0.0,1.0]
                    -t Weight threshold (default 0)
                    -k Keep class rate (default 0.0)
                    -m Mutation mode [dec|constant] value(pos.real)
                    -d Number of iterations x>0 (default x=20).
                    -o Writes clustering to filename.
                    filename    The filename for output.
                    -O Writes clustering into database specified in CW_DBproperties.ini.
                    -S Do not renumber input.
                    -R keep graph on disk (large graphs)

                    Documentation:
                    http://wortschatz.uni-leipzig.de/~cbiemann/software/toolbox/CW.html
                    -->
                    <command>java -Xmx500M -classpath .;./lib/ASV_CW.jar -Djava.ext.dirs=.;./lib de.uni_leipzig.asv.toolbox.ChineseWhispers.main.Start -F -i ${input} -o ${output}</command>
                    <inputs>
                        <input name="input">
                            <Datatype>xsd:anyURI</Datatype>
                            <Required>true</Required>
                            <CliMapping>input</CliMapping>
                            <Documentation>URL reference to input file</Documentation>
                            <Default>https://github.com/impactcentre/iif-testfiles/raw/master/testfiles/7lang_nodes.txt</Default>
                        </input>
                    </inputs>
                    <outputs>
                        <output name="output">
                            <Datatype>xsd:anyURI</Datatype>
                            <Required>false</Required>
                            <CliMapping>outputdir</CliMapping>
                            <Documentation>URL reference to output file</Documentation>
                        </output>
                    </outputs>
                </operation>
            </operations>
            <deployto>
                <deployref default="true" ref="local"/>
            </deployto>
        </service>
		<service sid="2" name="ASV_levenshtein" type="migrate" servicepackage="eu.impact_project.iif.service" contextpathprefix="/impactservices">
            <description>Services for verifying a words spelling and finding prosecutions for this word</description>
            <operations>
                <operation oid="1" name="levenshtein">
                    <description>Verify a words spelling and find prosecutions</description>
                    <!--
                    Usage:
                    java -Xmx500M -classpath .; ./lib/ASV_Levenshtein.jar -Djava.ext.dirs=.;.lib de.uni_leipzig.asv.toolbox.levenshtein.Levenshtein -C -i ./resources/levenshtein/plain/wordlist_de.txt -o ./examples/de_cli.dawg

                    -? Print this information.
                    -C Create a word graph from file (-i) or from a database.
                    -g Start gui mode.
                    -w Specify the word to check. (Use with -f)
                    -f Specify the dawg file to use.
                    -i Specify the file containing words. (Use with -C).
                    -o Save output to the specified file.
                    -l Levenshtein distance to use. (default is 1)
                    -D Specify the driver (default is com.mysql.jdbc.Driver).
                    -P Specify the protocol (default is mysql).
                    -h Specify the database host (default is localhost).
                    -x Set the port to use. (default is 3306).
                    -d Specify the database
                    -u Database user name.
                    -p The user's password.
                    -t Specify the table.
                    -W Specify the table's column which contains the words.
                    -c Specify the table's column which contains the word ids.
                    -I Specify the lowest word id. (default is 101)
                    -O Specify the numbers of words. (default is 2000)

                    Documentation:
                    http://wortschatz.uni-leipzig.de/~cbiemann/software/toolbox/Levensthein.htm
                    -->
                    <command>java -Xmx500M -classpath .;./lib/ASV_Levenshtein.jar -Djava.ext.dirs=.;./lib de.uni_leipzig.asv.toolbox.levenshtein.Levenshtein -C -i ${input} -o ${output}</command>
                    <inputs>
                        <input name="input">
                            <Datatype>xsd:anyURI</Datatype>
                            <Required>true</Required>
                            <CliMapping>input</CliMapping>
                            <Documentation>URL reference to input file</Documentation>
                            <Default>https://github.com/impactcentre/iif-testfiles/raw/master/testfiles/wordlist_de.txt</Default>
                        </input>
                    </inputs>
                    <outputs>
                        <output name="output">
                            <Datatype>xsd:anyURI</Datatype>
                            <Required>false</Required>
                            <CliMapping>outputdir</CliMapping>
                            <Documentation>URL reference to output file</Documentation>
                        </output>
                    </outputs>
                </operation>
            </operations>
            <deployto>
                <deployref default="true" ref="local"/>
            </deployto>
        </service>
		<service sid="3" name="ASV_baseforms" type="migrate" servicepackage="eu.impact_project.iif.service" contextpathprefix="/impactservices">
            <description>Services for reducing inflected word forms to their base form and splitting compound nouns</description>
            <operations>
                <operation oid="1" name="baseforms">
                    <description>Reduce inflected word forms to their base form and split compound nouns</description>
                    <!--
                    Usage:
                   java -classpath .;./lib/ASV_Baseforms.jar -Djava.ext.dirs=.;./lib de.uni_leipzig.asv.toolbox.baseforms.BaseformsCL -cnd -i Baumschule -l German -o

                    -help print this help
                    -br baseform reduction
                    -cnd compound noun decomposition

                    Options:
                    -i word input a word
                    -if file input a wordfile
                    -o output at screen
                    -of file output in specified file
                    -l lang choose a language
                    -rt file load a reduction tree from specified file

                    following option are only for baseform reduction:
                    -wf worform choose a wordform

                    following options are only for compound noun decomposition:
                    -ft file load a forward tree from the specified file
                    -bt file load a backward tree from the specified file

                    Documentation:
                    http://wortschatz.uni-leipzig.de/~cbiemann/software/toolbox/Baseforms%20Tool.htm
                    -->
                    <command>java -classpath .;./lib/ASV_Baseforms.jar -Djava.ext.dirs=.;./lib de.uni_leipzig.asv.toolbox.baseforms.BaseformsCL -cnd -if ${input} -l {language} -of ${output}</command>
                    <inputs>
                        <input name="input">
                            <Datatype>xsd:anyURI</Datatype>
                            <Required>true</Required>
                            <CliMapping>input</CliMapping>
                            <Documentation>URL reference to input file</Documentation>
                            <Default>https://github.com/impactcentre/iif-testfiles/raw/master/testfiles/word_de.txt</Default>
                        </input>
			            <input name="language">
			                <Datatype>xsd:string</Datatype>
                            <Required>true</Required>
                            <CliMapping>language</CliMapping>
                            <Documentation>Language model</Documentation>
                            <Default>German</Default>
			            </input>
                        </inputs>
                    <outputs>
                        <output name="output">
                            <Datatype>xsd:anyURI</Datatype>
                            <Required>false</Required>
                            <CliMapping>outputdir</CliMapping>
                            <Documentation>URL reference to output file</Documentation>
                        </output>
                    </outputs>
                </operation>
            </operations>
            <deployto>
                <deployref default="true" ref="local"/>
            </deployto>
        </service>
		<service sid="4" name="ASV_pretree" type="migrate" servicepackage="eu.impact_project.iif.service" contextpathprefix="/impactservices">
            <description>Services for classifying words with Pretrees, evaluating your Pretree with a word set and creating Pretrees from your data</description>
            <operations>
                <operation oid="1" name="pretree">
                    <description>Classify words with Pretrees, evaluate your Pretree with a word set and create Pretrees from your data</description>
                    <!--
                    Usage:
                    java -classpath .;./lib/ASV_Pretree.jar -Djava.ext.dirs=.;./lib de.uni_leipzig.toolbox.pretree.PretreeTool [commands][options] [parameters]

                    train, t: trains a pretree from a map file and save it to a tree file
                            java de.uni_leipzig.toolbox.pretree.PretreeTool t [options] <mapfile> <treefile>
                    prune, p: prune a pretree given as a tree file and save it to another tree file
                            java de.uni_leipzig.toolbox.pretree.PretreeTool p [options] <treefile_not_pruned> <treefile_pruned>
                    trainprune, tp: train and prune a pretree from a map file and save it to a tree file
                            java de.uni_leipzig.toolbox.pretree.PretreeTool tp [options] <mapfile> <treefile>
                    classify, c: classifies a word with the tree from a given tree file
                            java de.uni_leipzig.toolbox.pretree.PretreeTool c [options] <word> <treefile>
                    convert, cv: converts trees in the given tree files in to the latest format
                            java de.uni_leipzig.toolbox.pretree.PretreeTool cv [options] <treefile_0> <treefile_1> \85 <treefile_n>
                    print, pr: print out the pretrees that are given in the tree files
                            java de.uni_leipzig.toolbox.pretree.PretreeTool pr [options] <treefile_0> <treefile_1> \85 <treefile_n>

                    Options:
                    [options] could be replaced through following commands

                    -t=#: sets the threshold for classifying to #, this should be a value between 0 and 1
                    -f: can be used only with the command classify, c : instead of single word all words from a word will are taken for classification, -f must appear directly before the absolute path to the word file

                    the following options are only for commands train and trainprune
                    -rv: reverse tree
                    -ic: ignore case
                    -sc=#: character # as first \93number\94, default: 33
                    -ec=#: character # as last \93number\94, default: 248
                    -az=#: character # as number separator, default: 2
                    -ak=#: character # as node separator, default: 3

                    Documentation:
                    http://wortschatz.uni-leipzig.de/~cbiemann/software/toolbox/Pretree.html
                    -->
                    <command>java -classpath .;./lib/ASV_Pretree.jar -Djava.ext.dirs=.;./lib de.uni_leipzig.toolbox.pretree.PretreeTool trainprune ${input} ${output}</command>
                    <inputs>
                        <input name="input">
                            <Datatype>xsd:anyURI</Datatype>
                            <Required>true</Required>
                            <CliMapping>input</CliMapping>
                            <Documentation>URL reference to input file</Documentation>
                            <Default>https://github.com/impactcentre/iif-testfiles/raw/master/testfiles/de-BaseRulesV.txt</Default>
                        </input>
                    </inputs>
                    <outputs>
                        <output name="output">
                            <Datatype>xsd:anyURI</Datatype>
                            <Required>false</Required>
                            <CliMapping>outputdir</CliMapping>
                            <Documentation>URL reference to output file</Documentation>
                        </output>
                    </outputs>
                </operation>
            </operations>
            <deployto>
                <deployref default="true" ref="local"/>
            </deployto>
        </service>
		<service sid="5" name="ASV_terminologyExtraction" type="migrate" servicepackage="eu.impact_project.iif.service" contextpathprefix="/impactservices">
            <description>Services for extracting technical terms from a given text for use in terminological databases and dictionaries</description>
            <operations>
                <operation oid="1" name="terminologyExtraction">
                    <description>Extract technical terms from a given text for use in terminological databases and dictionaries</description>
                    <!--
                    Usage:
                    java -Xmx500M -classpath .;./lib/ASV_TE.jar -Djava.ext.dirs=.;./lib de.uni_leipzig.asv.toolbox.te.TETool [OPTIONS] TEXTFILE [TERMSFILE]

                    -l=# --language=# specifies the language of the text; possible: en, de; default: en
                    -ft=# --min_freq_text=# sets minimum frequency of a word in the text to be taken into account to #, default 1
                    -fc=# --min_freq_corpus=# sets minimum frequency of a word in the corpus to be taken into account to #, default 2
                    -ms=# --min_significance=# sets minimum significane of a word to be taken into account to #, default 20.0
                    -sm=# --sig_measure=# specifies the significances measure; possible: lr (likelihood ratio), fr (frequency ratio); default: lr
                    -s --show_significances show significances

                    Documentation:
                    http://wortschatz.uni-leipzig.de/~cbiemann/software/toolbox/TE.html
                    -->
                    <command>java -Xmx500M -classpath .;./lib/ASV_TE.jar -Djava.ext.dirs=.;./lib de.uni_leipzig.asv.toolbox.te.TETool -l=de -s ${input} ${output}</command>
                    <inputs>
                        <input name="input">
                            <Datatype>xsd:anyURI</Datatype>
                            <Required>true</Required>
                            <CliMapping>input</CliMapping>
                            <Documentation>URL reference to input file</Documentation>
                            <Default>https://github.com/impactcentre/iif-testfiles/raw/master/testfiles/text_deutsch.txt</Default>
                        </input>
                    </inputs>
                    <outputs>
                        <output name="output">
                            <Datatype>xsd:anyURI</Datatype>
                            <Required>false</Required>
                            <CliMapping>outputdir</CliMapping>
                            <Documentation>URL reference to output file</Documentation>
                        </output>
                    </outputs>
                </operation>
            </operations>
            <deployto>
                <deployref default="true" ref="local"/>
            </deployto>
        </service>
		<service sid="6" name="ASV_pendulum" type="migrate" servicepackage="eu.impact_project.iif.service" contextpathprefix="/impactservices">
            <description>Services for finding named entities by bootstrapping</description>
            <operations>
                <operation oid="1" name="pendulum">
                    <description>Find named entities by bootstrapping</description>
                    <!--
                    Usage:
                    java -Xmx500M -classpath .;./lib/ASV_Pendulum.jar -Djava.ext.dirs=.;./lib de.uni_leipzig.asv.toolbox.pendel.PendelCL configfile -o outputfile [-t]

                    configfile path to the configuration file which should be used for the run
                    -o outputfile path to the output file in which the output will be written
                    -t use the internal tokenizer

                    Documentation:
                    http://wortschatz.uni-leipzig.de/~cbiemann/software/toolbox/Pendulum.html
                    -->
                    <command>java -Xmx500M -classpath .;./lib/ASV_Pendulum.jar -Djava.ext.dirs=.;./lib de.uni_leipzig.asv.toolbox.pendel.PendelCL ${input} -o ${output} -t</command>
                    <inputs>
                        <input name="input">
                            <Datatype>xsd:anyURI</Datatype>
                            <Required>true</Required>
                            <CliMapping>input</CliMapping>
                            <Documentation>URL reference to config file</Documentation>
                            <Default>https://github.com/impactcentre/iif-testfiles/raw/master/testfiles/Pendel_localhost.cfg</Default>
                        </input>
                    </inputs>
                    <outputs>
                        <output name="output">
                            <Datatype>xsd:anyURI</Datatype>
                            <Required>false</Required>
                            <CliMapping>outputdir</CliMapping>
                            <Documentation>URL reference to output file</Documentation>
                        </output>
                    </outputs>
                </operation>
            </operations>
            <deployto>
                <deployref default="true" ref="local"/>
            </deployto>
        </service>
		<service sid="7" name="ASV_namerec" type="migrate" servicepackage="eu.impact_project.iif.service" contextpathprefix="/impactservices">
            <description>Services for finding named entities by bootstrapping</description>
            <operations>
                <operation oid="1" name="pendulum">
                    <description>Find named entities by bootstrapping</description>
                    <!--
                    Usage:
                    java -Xmx500M -classpath .;./lib/ASV_Namerec.jar -Djava.ext.dirs=.;./lib de.uni_leipzig.asv.toolbox.namerec.Recognizer configfile [-t -rn] [-o outfile] db|file|sentence [filename|sentence]

                    configfile - path to a configuration file of this tool containing the settings for this run
                    -t use tokenizer
                    -rn replace numbers
                    -o outputfile write output to file outputfile, if not specified written to console
                    db use sentences from database for run(configured in configfile)
                    file (needs filename behind separated by space) use sentences from file filename for run
                    sentence (needs sentence behind separated by space) use the specified sentence for run

                    Documentation:
                    http://wortschatz.uni-leipzig.de/~cbiemann/software/toolbox/Namerec.html
                    -->
                    <command>java -Xmx500M -classpath .;./lib/ASV_Namerec.jar -Djava.ext.dirs=.;./lib de.uni_leipzig.asv.toolbox.namerec.Recognizer ${config} -t -o ${output} file ${input}</command>
                    <inputs>
                        <input name="input">
                            <Datatype>xsd:anyURI</Datatype>
                            <Required>true</Required>
                            <CliMapping>input</CliMapping>
                            <Documentation>URL reference to input file</Documentation>
                            <Default>https://github.com/impactcentre/iif-testfiles/raw/master/testfiles/Namerec.txt</Default>
                        </input>
			            <input name="config">
                            <Datatype>xsd:anyURI</Datatype>
                            <Required>true</Required>
                            <CliMapping>config</CliMapping>
                            <Documentation>URL reference to config file</Documentation>
                            <Default>https://github.com/impactcentre/iif-testfiles/raw/master/testfiles/NameRec_noWriteback.cfg</Default>
                        </input>
                    </inputs>
                    <outputs>
                        <output name="output">
                            <Datatype>xsd:anyURI</Datatype>
                            <Required>false</Required>
                            <CliMapping>outputdir</CliMapping>
                            <Documentation>URL reference to output file</Documentation>
                        </output>
                    </outputs>
                </operation>
            </operations>
            <deployto>
                <deployref default="true" ref="local"/>
            </deployto>
        </service>
		<service sid="8" name="ASV_jlani" type="migrate" servicepackage="eu.impact_project.iif.service" contextpathprefix="/impactservices">
            <description>Services for identifying the language of sentences</description>
            <operations>
                <operation oid="1" name="jlani">
                    <description>Identify the language of sentences</description>
                    <!--
                    Usage:
                    java -Xmx500M -classpath .;./lib/ASV_JLanI.jar -Djava.ext.dirs=.;./lib de.uni_leipzig.asv.toolbox.jLanI.main.CLIMain <inFile> <outFile>

                    <inFile> here you have to specify the path of the input file, e.g c:\input.txt
                    <outFile> here you have to specify the path of the output file, e.g. c:\output.txt

                    Documentation:
                    http://wortschatz.uni-leipzig.de/~cbiemann/software/toolbox/JLanI.htm
                    -->
                    <command>java -Xmx500M -classpath .;./lib/ASV_JLanI.jar -Djava.ext.dirs=.;./lib de.uni_leipzig.asv.toolbox.jLanI.main.CLIMain ${input} ${output}</command>
                    <inputs>
                        <input name="input">
                            <Datatype>xsd:anyURI</Datatype>
                            <Required>true</Required>
                            <CliMapping>input</CliMapping>
                            <Documentation>URL reference to input file</Documentation>
                            <Default>https://github.com/impactcentre/iif-testfiles/raw/master/testfiles/jLanI_text.txt</Default>
                        </input>
                    </inputs>
                    <outputs>
                        <output name="output">
                            <Datatype>xsd:anyURI</Datatype>
                            <Required>false</Required>
                            <CliMapping>outputdir</CliMapping>
                            <Documentation>URL reference to output file</Documentation>
                        </output>
                    </outputs>
                </operation>
            </operations>
            <deployto>
                <deployref default="true" ref="local"/>
            </deployto>
        </service>
		<service sid="9" name="ASV_viterbiTagger" type="migrate" servicepackage="eu.impact_project.iif.service" contextpathprefix="/impactservices">
            <description>Services for training a Viterbitagger from tagged text in horizontal and vertical format with one or two tags per word</description>
            <operations>
                <operation oid="1" name="viterbiTagger">
                    <description>Train a Viterbitagger from tagged text in horizontal and vertical format with one or two tags per word</description>
                    <!--
                    Usage:
                    java -Xmx500M -classpath .;./lib/ASV_Viterbitagger.jar -Djava.ext.dirs=.;./lib de.uni_leipzig.asv.toolbox.viterbitagger.gui.ViterbitaggerCL ability option [options ...]

                    Abilities
                    train for training a Viterbitagger
                    tag for tag with a given Viterbitagger model some text
                    evaluate for evaluate a given Viterbitagger model with a file

                    Options:
                    -tm taggermodelfile the taggermodel which will be used(tag/evaluate) or which will be created(train)
                    only for train:
                    -db train from db, uses configuration from config/viterbiTagger/viterbiTagger.query
                    -f file train from the given file
                    -h file is in horizontal file format else file is in vertical file format
                    -s seperator sign between word and tag, use this only together with -h option
                    -set sentenceendtag tag for the end of a sentence, use this only without -h option
                    -rn replace numbers option
                    -wp word position, default 1
                    -ptp primary tag position, default 2
                    -stp secondary tag position, -1 means not in use, default \961
                    only for tag and evaluate:
                    -ram viterbitagger will be loaded complete into RAM(faster) else part of the tagger will be on disk(for small RAM)
                    only for tag:
                    -tokenizer uses tokenizer before tag the text
                    -if infile specify the input file for tagging
                    -of outfile specify the output file for tagging
                    -it use this option for input from console
                    -ot print tagged text to screen
                    -idb use db for input, uses configuration from config/viterbiTagger/viterbiTagger.query
                    -odb write tagged sentences back to db, uses configuration from config/viterbiTagger/viterbiTagger.query
                    -ids start id for tagging sentences from database, default 0
                    -ide end id for tagging sentences from database, -1 means all, default \961
                    only use for evaluate:
                    -ef evaluatefile specify the file for evaluation

                    Documentation:
                    http://wortschatz.uni-leipzig.de/~cbiemann/software/toolbox/Viterbitagger.htm
                    -->
                    <command>java -Xmx500M -classpath .;./lib/ASV_Viterbitagger.jar -Djava.ext.dirs=.;./lib de.uni_leipzig.asv.toolbox.viterbitagger.gui.ViterbitaggerCL tag -tm ./examples/tagger/clTaggermodelhor.model -tokenizer -if ${input} -of ${output} -ram -ot</command>
                    <inputs>
                        <input name="input">
                            <Datatype>xsd:anyURI</Datatype>
                            <Required>true</Required>
                            <CliMapping>input</CliMapping>
                            <Documentation>URL reference to input file</Documentation>
                            <Default>https://github.com/impactcentre/iif-testfiles/raw/master/testfiles/text_englisch.txt</Default>
                        </input>
                    </inputs>
                    <outputs>
                        <output name="output">
                            <Datatype>xsd:anyURI</Datatype>
                            <Required>false</Required>
                            <CliMapping>outputdir</CliMapping>
                            <Documentation>URL reference to output file</Documentation>
                        </output>
                    </outputs>
                </operation>
            </operations>
            <deployto>
                <deployref default="true" ref="local"/>
            </deployto>
        </service>
		<service sid="10" name="ASV_zipfel" type="migrate" servicepackage="eu.impact_project.iif.service" contextpathprefix="/impactservices">
            <description>Services for demonstrating Zipf\92s law</description>
            <operations>
                <operation oid="1" name="zipfel">
                    <description>Demonstrate Zipf\92s law</description>
                    <!--
                    Usage:
                    java -classpath .;./lib/ASV_Zipfel.jar -Djava.ext.dirs=.;./lib de.uni_leipzig.toolbox.zipfel.ZipfelCmdLine [parameter \85]

                    -host <host> host of your database
                    -port <port; default=3306> port of the database
                    -user <user> your user name of the database
                    -pw <password> your password of the database
                    -db <database> database containing data for Zipfel
                    -table <database table> table on which Zipfel should run
                    -wordcol <column containing words or word numbers> column containing the words or their word numbers for Zipfel
                    -countcol <column containing frequency> column containing the frequency of the words
                    -where <restriction using where; embed in quotation marks> This option allow you to specify a where clause for restricting the data
                    -filenamediagram <output file for diagram in png format> absolute path of the output file in png format
                    -filenametablecsv <output file for table in csv format> absolute path of the output file in csv format
                    -filenametableods <output file for table in open document format> absolute path of the output file in open document format

                    command line output will be in the following format :
                    [restriction of the selection] TAB types TAB tokens TAB k TAB c TAB a TAB b

                    Documentation:
                    http://wortschatz.uni-leipzig.de/~cbiemann/software/toolbox/Zipfel.htm
                    -->
                    <command>java -classpath .;./lib/ASV_Zipfel.jar -Djava.ext.dirs=.;./lib de.uni_leipzig.toolbox.zipfel.ZipfelCmdLine -host localhost -port 3306 -user root -pw root -db {input} -table words -wordcol word -countcol freq -filenamediagram ${output}</command>
                    <inputs>
                        <input name="input">
                            <Datatype>xsd:string</Datatype>
                            <Required>true</Required>
                            <CliMapping>input</CliMapping>
                            <Documentation>Reference to input database</Documentation>
                            <Default>de1M</Default>
                        </input>
                    </inputs>
                    <outputs>
                        <output name="output">
                            <Datatype>xsd:anyURI</Datatype>
                            <Required>false</Required>
                            <CliMapping>outputdir</CliMapping>
                            <Documentation>URL reference to output file</Documentation>
                        </output>
                    </outputs>
                </operation>
            </operations>
            <deployto>
                <deployref default="true" ref="local"/>
            </deployto>
        </service>
		<service sid="11" name="ASV_hac" type="migrate" servicepackage="eu.impact_project.iif.service" contextpathprefix="/impactservices">
            <description>Services that can be used to create a clustering of objects</description>
            <operations>
                <operation oid="1" name="hac">
                    <description>Create a clustering of objects</description>
                    <!--
                    Usage:
                    java -classpath .;./lib/ASV_HAC.jar -Djava.ext.dirs=./lib de.uni_leipzig.asv.toolbox.hac.main.CLIMain --test -o "1_clustering_output_test" -x -v Cosine -c SingleLinkage

                    -?, --help  		print this help
                    -g  --gui   		starts the GUI of this clustering tool.
                                This ignores all other command-line parameters, except any specified property file
                    -t  --threads <nr>          number of background threads that should be used for calculations (default is 1)

                    Datasources (Hint only ONE datasource may be used!):
                    -v  --vectorfile <filename> uses the vector file indicated by <filename> as datasource
                    --compact               	indicates that the file is in short/compact format (default)
                    --explicit              	indicates that the file in in long/explicit format
                    --wordserv <filename>   	indicates that the vector names should be retrieved from the wordserver file indicated by <filename>
                    -d  --database              uses a database connection as datasource.
                    -f  --textfile <filename>   uses the text file indicated by <filename> as word list source along with a database connection to retrieve feature vectors
                    --propfile <filename>   	indicates that database connection and input settings should be loaded from the property file <filename>
                    --restrictrange         	indicates that candidate words must have database IDs within a certain range, as defined in the property file. Other words will be excluded. If omitted (default), range will not be restricted.
                    --restrictfreq          	indicates that candidate words must have database frequencies within a certain range, as defined in the property file. Other words will be excluded. If omitted (default), frequency will not be restricted.
                    --applyfeatureminsig    	indicates that feature vector elements must have a minimum significance, whose value is specified in the property file. If omited (default), this minimum is not considered.
                    --applyfeaturelimit     	indicates that only a number of most significant features be used as feature vector elements. This number is specified in the property file. If omited (default), all available features are used as feature vector elements.
                    -u  --user <username>       the database user name
                    -p  --password <password>   the database password
                    --test                  	use randomly created test data

                    Output options:
                    -o  --out <filename>        the filename for output without extension! For example, using myout you will get myout.png for dendrogram or myout.xml for xml output (or both)
                    --disabledendrogram     	disable dendrogram drawing (enabled by default)
                    -x  --xml                   enable xml output (disabled by default)
                    --depth <int>           	the depth for xml output: number of top cluster levels

                    Algorithm options:
                    -v  --vectordist <dist>     set the vector distance, possible distances are:
                                L1 Norm
                                L2 Norm
                                Cosine
                                Dice
                                Jaccard
                    -c  --cluster <dist>        set the cluster distance, possible distances are:
                                SingleLinkage
                                CompleteLinkage
                                AverageLinkage
                                AvgGroupLinkage
                                CentroidMethod
                                WardsMethod

                    Documentation:
                    http://wortschatz.uni-leipzig.de/~cbiemann/software/toolbox/HAC.html
                    -->
                    <command>java -classpath .;./lib/ASV_HAC.jar -Djava.ext.dirs=./lib de.uni_leipzig.asv.toolbox.hac.main.CLIMain -f ${input} -q my_clustering.properties -o ${output} -x -v Cosine -c AverageLinkage</command>
                    <inputs>
                        <input name="input">
                            <Datatype>xsd:anyURI</Datatype>
                            <Required>true</Required>
                            <CliMapping>input</CliMapping>
                            <Documentation>URL reference to input file</Documentation>
                            <Default>https://github.com/impactcentre/iif-testfiles/raw/master/testfiles/wortschatz.uni-leipzig.de_asv.htm</Default>
                        </input>
                    </inputs>
                    <outputs>
                        <output name="output">
                            <Datatype>xsd:anyURI</Datatype>
                            <Required>false</Required>
                            <CliMapping>outputdir</CliMapping>
                            <Documentation>URL reference to output file</Documentation>
                        </output>
                    </outputs>
                </operation>
            </operations>
            <deployto>
                <deployref default="true" ref="local"/>
            </deployto>
        </service>
		<service sid="12" name="ASV_genetomorph" type="migrate" servicepackage="eu.impact_project.iif.service" contextpathprefix="/impactservices">
            <description>Services for using a genetic algorithm to find morphologic structure, so called morphemes</description>
            <operations>
                <operation oid="1" name="genetomorph">
                    <description>Use a genetic algorithm to find morphologic structure</description>
                    <!--
                    Usage:
                    java -Xmx500M -classpath .;./lib/ASV_Genetomorph.jar -Djava.ext.dirs=.;./lib de.uni_leipzig.asv.toolbox.genetoMorph.GenetoMorphCL -i inputfile [-o outputfile -nc numberOfChildren -mr mutationrate -sc simulationCycles -ee]

                    -i inputfile specify the absolut path to the input file
                    -o outputfile specify the absolute path to the output file, if not specified output will print to screen(default: print to screen)
                    -nc NumberOfChildren specify the number of children for one simulation cycle, should be an integer(default: 10)
                    -mr muatationrate specify the mutation rate for the simulation, should be an integer(default: 1)
                    -sc simulationCycles specify the number of simulation cycles for this run(default 10)
                    -ee eliminate equals individuals, (default: not choosen)

                    Documentation:
                    http://wortschatz.uni-leipzig.de/~cbiemann/software/toolbox/Genetomorph.html
                    -->
                    <command>java -Xmx500M -classpath .; ./lib/ASV_Genetomorph.jar -Djava.ext.dirs=.;./lib de.uni_leipzig.asv.toolbox.genetoMorph.GenetoMorphCL -i ${input} -nc 30 -mr 5 -sc 50 -ee -o ${output}</command>
                    <inputs>
                        <input name="input">
                            <Datatype>xsd:anyURI</Datatype>
                            <Required>true</Required>
                            <CliMapping>input</CliMapping>
                            <Documentation>URL reference to input file</Documentation>
                            <Default>https://github.com/impactcentre/iif-testfiles/raw/master/testfiles/training.txt</Default>
                        </input>
                    </inputs>
                    <outputs>
                        <output name="output">
                            <Datatype>xsd:anyURI</Datatype>
                            <Required>false</Required>
                            <CliMapping>outputdir</CliMapping>
                            <Documentation>URL reference to output file</Documentation>
                        </output>
                    </outputs>
                </operation>
            </operations>
            <deployto>
                <deployref default="true" ref="local"/>
            </deployto>
        </service>
    </services>
    <deployments>
        <deployment id="local">
            <identifier>http://localhost:8080/impact/instances/tomcat1</identifier>
            <host>localhost</host>
            <ports>
                <port type="http">8080</port>
                <port type="https">8043</port>
            </ports>
            <manager>
                <user>tomcat</user>
                <password>tomcat</password>
                <path>manager</path>
            </manager>
            <!--
            Full path to the directory where the tool has been installed.
            THE PATH MUST NOT CONTAIN WHITESPACES!
            If you want to use backslashes (\) then you must repeat them twice,
            e.g. c:\\foo\\bar
            or you can use just slashes,
            e.g. c:/foo/bar
            -->
            <toolsbasedir></toolsbasedir>
            <dataexchange>
                <accessdir>../webapps/ROOT/impact/tmp/</accessdir>
                <accessurl>http://localhost:8080/impact/tmp/</accessurl>
            </dataexchange>
        </deployment>
    </deployments>
</toolspec>
